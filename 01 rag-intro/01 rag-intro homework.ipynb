{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0cc92fa-9db2-42a1-889e-1aa7fd3d62dc",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da7190a",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313d39d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import tiktoken\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from elasticsearch import Elasticsearch\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Any, Dict, List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee37727-033f-46fd-a4fa-6970198b783a",
   "metadata": {},
   "source": [
    "### Getting FAQ document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d63c7f8-d587-4d03-b1e1-aef3bd131c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab95af4-ea55-4504-8686-9ed3d0f52641",
   "metadata": {},
   "source": [
    "### Preparing OpenAI client and RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d2e869-1180-4fe2-aa7e-a6ba5f88ce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec3b552-ad1e-4325-935e-99ec7c162327",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    base_url=os.getenv('OPENAI_PROXY_URL'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0147dec0-5df5-470b-b7e5-464e52ef3545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a response based on the input prompt using GPT-4O.\n",
    "\n",
    "    This method sends a user message to the GPT-4O chat completions API,\n",
    "    receives a response, and extracts the content of the first choice made by the AI.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    prompt : str\n",
    "        The user's message or prompt to which the AI will respond.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The content of the AI's response as a string.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dd67d80-07b5-410d-a27c-980a2a4036f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Performs a research assistant task given a query.\n",
    "\n",
    "    This method searches for relevant information using Elasticsearch,\n",
    "    builds a prompt based on the search results, generates an answer using a language model,\n",
    "    and returns the generated answer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query : str\n",
    "        The user's query or question to which the research assistant will respond.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The generated answer as a string.\n",
    "    \"\"\"\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed5542e-2b73-4282-9313-1978a7616bb9",
   "metadata": {},
   "source": [
    "### Prepare Elasticsearch client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdb453ca-3473-4163-8902-bb258156a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e7e6f4-b87a-4620-adc7-9046fa221091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-homework'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "index_name = \"course-homework\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5bf09f6-4a32-47a4-9014-5c227103a9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b13c22f1f045358312824a56d90fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248f4bfd-999d-4fe2-b7fc-cb568ceaa060",
   "metadata": {},
   "source": [
    "## [Homework questions](https://github.com/DataTalksClub/llm-zoomcamp/blob/main/cohorts/2024/01-intro/homework.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da35eed-cf16-41c3-8f73-5351ad9808ca",
   "metadata": {},
   "source": [
    "### [Q1. Running Elastic](https://github.com/DataTalksClub/llm-zoomcamp/blob/main/cohorts/2024/01-intro/homework.md#q1-running-elastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbe021e0-dbbc-4e90-8a93-2cbab73e12be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: 42f05b9372a9a4a470db3b52817899b99a76ee73\n"
     ]
    }
   ],
   "source": [
    "print('Q1:', es_client.info()['version']['build_hash'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b741b42f-ef5e-4cbc-ae0d-fb94e65d2b35",
   "metadata": {},
   "source": [
    "### [Q2. Indexing the data](https://github.com/DataTalksClub/llm-zoomcamp/blob/main/cohorts/2024/01-intro/homework.md#q2-indexing-the-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd7e464f-d02f-4be8-ae69-647bd5982e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2: index\n"
     ]
    }
   ],
   "source": [
    "print('Q2: index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55f6d19-1edf-4175-903b-2fcbb6117fb5",
   "metadata": {},
   "source": [
    "### [Q3. Searching](https://github.com/DataTalksClub/llm-zoomcamp/blob/main/cohorts/2024/01-intro/homework.md#q3-searching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aebc2d56-a335-4c48-87cb-1992f3c88185",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How do I execute a command in a running docker container?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09ec343c-8070-433a-95db-2a9067537199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Searches Elasticsearch for documents matching a given query and returns their scores.\n",
    "\n",
    "    This method constructs a search query targeting documents related to \"data-engineering-zoomcamp\",\n",
    "    executes the search against Elasticsearch, and collects the scores of the top matches.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query : str\n",
    "        The search query to be executed against Elasticsearch.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[float]\n",
    "        A list of scores corresponding to the relevance of the top search results.\n",
    "    \"\"\"\n",
    "    search_query = {\n",
    "        \"size\": 1,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\",\n",
    "                    },\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"data-engineering-zoomcamp\"\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_score'])\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d486163-2381-4479-8cea-66920a9503c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3: Top score is 75.54128\n"
     ]
    }
   ],
   "source": [
    "print('Q3: Top score is', elastic_search(query)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13137402-acb5-41c9-b2a5-2fc7a16f26af",
   "metadata": {},
   "source": [
    "### [Q4. Filtering](https://github.com/DataTalksClub/llm-zoomcamp/blob/main/cohorts/2024/01-intro/homework.md#q4-filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b2acd76-4c76-404f-b33e-70d26232b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Searches Elasticsearch for documents matching a given query and returns their contents.\n",
    "\n",
    "    This method constructs a search query targeting documents related to \"machine-learning-zoomcamp\",\n",
    "    executes the search against Elasticsearch, and collects the contents (_source) of the top matches.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query : str\n",
    "        The search query to be executed against Elasticsearch.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[Dict[str, Any]]\n",
    "        A list of dictionaries representing the contents of the top search results.\n",
    "    \"\"\"\n",
    "    search_query = {\n",
    "        \"size\": 3,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\",\n",
    "                    },\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"machine-learning-zoomcamp\"\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d8f5bfa-a3cb-4ace-bc08-cfb365c2ec28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4: How do I copy files from a different folder into docker container’s working directory?\n"
     ]
    }
   ],
   "source": [
    "search_results = elastic_search(query)\n",
    "q4_result = search_results[2]\n",
    "print('Q4:', q4_result['question'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19403b1e-b382-446e-9eca-1253b965a606",
   "metadata": {},
   "source": [
    "### [Q5. Building a prompt](https://github.com/DataTalksClub/llm-zoomcamp/blob/main/cohorts/2024/01-intro/homework.md#q5-building-a-prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3043dd0-04f3-47f4-9138-ece932d51ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query: str, search_results: List[Dict[str, str]]) -> str:\n",
    "    \"\"\"\n",
    "    Constructs a prompt for a language model based on a query and search results.\n",
    "\n",
    "    This method formats a query and search results into a structured prompt,\n",
    "    designed to guide a language model in generating an answer based on the provided context.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query : str\n",
    "        The question or query to be answered.\n",
    "    search_results : List[Dict[str, str]]\n",
    "        A list of dictionaries, each containing a question and its corresponding answer.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A formatted prompt that combines the question with the context from the search results.\n",
    "    \"\"\"\n",
    "    context_template = '''\n",
    "Q: {question}\n",
    "A: {text}\n",
    "'''.strip()\n",
    "    \n",
    "    prompt_template = '''\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "'''.strip()\n",
    "\n",
    "    context = ''\n",
    "    for doc in search_results:\n",
    "        context = context + context_template.format(\n",
    "            question=doc['question'],\n",
    "            text=doc['text']\n",
    "        ) + '\\n\\n'\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5775e757-049e-4859-8c78-6ba3b18e776a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5: 1462\n"
     ]
    }
   ],
   "source": [
    "prompt = build_prompt(query, search_results)\n",
    "\n",
    "print('Q5:', len(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c379de94-807b-4368-9ed5-674943b4ec03",
   "metadata": {},
   "source": [
    "### [Q6. Tokens](https://github.com/DataTalksClub/llm-zoomcamp/blob/main/cohorts/2024/01-intro/homework.md#q6-tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "642c8f25-82ec-4fd2-bf11-3f605f076f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_counter(prompt: str) -> int:\n",
    "    \"\"\"\n",
    "    Counts the number of tokens in a given prompt using the 'gpt-4o' model's encoding.\n",
    "\n",
    "    This method encodes the input prompt using the tokenization scheme associated with the 'gpt-4o' model,\n",
    "    and returns the total count of tokens in the encoded representation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    prompt : str\n",
    "        The input text whose token count is to be determined.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The total number of tokens in the encoded version of the input prompt.\n",
    "    \"\"\"\n",
    "    encoding = tiktoken.encoding_for_model('gpt-4o')\n",
    "    tokens = encoding.encode(prompt)\n",
    "\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e7e2518-219d-4e60-9329-e1c6a374a065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q6: 322 tokens\n"
     ]
    }
   ],
   "source": [
    "print('Q6:', token_counter(prompt), 'tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c925c2f6-24e2-4ec5-8303-4344fd78f8f1",
   "metadata": {},
   "source": [
    "### [Bonus: generating the answer](https://github.com/DataTalksClub/llm-zoomcamp/blob/main/cohorts/2024/01-intro/homework.md#bonus-generating-the-answer-ungraded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ab01869-261c-49e0-bf5c-9e28d485d4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To execute a command in a running Docker container, you can use the `docker exec` command. First, you need to identify the container ID of the running container by using the `docker ps` command. Once you have the container ID, you can execute a command inside that container. Here’s how you can do it:\\n\\n1. Find the container ID of the running container:\\n\\n```bash\\ndocker ps\\n```\\n\\n2. Execute the command inside the running container:\\n\\n```bash\\ndocker exec -it <container-id> <command>\\n```\\n\\nFor example, to start a bash session in the running container, you would use:\\n\\n```bash\\ndocker exec -it <container-id> bash\\n```'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66f3986-23ce-475e-a0ca-76c57cae877d",
   "metadata": {},
   "source": [
    "### [Bonus: calculating the costs](https://github.com/DataTalksClub/llm-zoomcamp/blob/main/cohorts/2024/01-intro/homework.md#bonus-calculating-the-costs-ungraded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b92ed535-c1f7-4f15-8e4c-db3bf17a9cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: 4.5$\n"
     ]
    }
   ],
   "source": [
    "result = (150 * 5 + 250 * 15) / 1_000_000 * 1_000\n",
    "\n",
    "print(f'Total cost: {result}$')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
